Như đã trình bày ở `docs/syllable_n_token.id.md` mọi syllable tiếng Việt và OOV trong corpus đều được định danh bằng `u15`. Để tiện cho máy tính xử lý theo byte ta dùng `u16` để định danh và dư ra ít nhất 32k slot để chứa từ quan trọng không phải là syllables (từ ghép, từ tiếng dân tộc thiểu số, từ vay mượn từ tiếng nước ngoài, từ lóng, từ viết tắt, các ký hiệu hay dùng ...) lọc ra bằng từ điển và thống kê.

Bài toán gộp âm tiết thành từ hay còn gọi là tách từ tiếng Việt đang thiếu và yếu, thiếu một quy chuẩn về mặt ngôn ngữ học là tách từ thế nào là hợp lý, thiếu một từ điển đủ bao quát và cập nhật, thiếu bộ corpus đủ lớn để học và đánh giá độ chính xác trong nhiều domains khác nhau. Vì vậy cách tiếp cận ở đây là đừng chạy theo accuracy hay tìm ra best solution, mà hãy sử dụng n-best hay aprroximate, hay pattern matching ...

Điểm chính ở đây là có nhiều cách trình bày và bài toán indexing, searching bao trùm tất cả các cách trình bày đó mà không cần phải chỉ ra đâu là cách trình bày tốt nhất. Tốt nhất hay không là tuỳ thuộc vào ngữ cảnh và mục đích sử dụng.

Ví dụ với câu "ông già đi nhanh quá" có 2 cách tách từ như sau:
1/ ông/N già/ADJ đi/N nhanh_quá/ADV
2/ ông/N già_đi/V nhanh_quá/ADV
Nếu không có context thì cả hai đều đúng và có giá trị như nhau.

Giả sử người dùng input "già đi nhanh", máy sẽ phân tích ra 3 bộ keywords để search như sau:
0/ già + đi + nhanh
1/ già_đi/V nhanh/ADV
2/ già/ADJ đi/V nhanh/ADV
(Bộ 0 là baseline, đúng trong mọi trường hợp :D)

Hiện kết quả của cả 2 cách phân tích và hỏi lại người dùng xem họ chọn cách nào. Nếu cả 2 cách ko thoả mãn người dùng thì show baseline.

Cách này áp dụng trong cả inverted indexing và word2vec.

- - -

Để giới hạn không gian ids trong `u16`, bộ từ điển tối đa có thể sử dụng là 32k từ.

- - -

Để sử dụng bộ từ điển nhiều từ hơn cần mở rộng số lượng tokens cần index, hoặc sử dụng positional index (đằng nào cũng phải dùng với sub-word tokens).

Tuy nhiên mở rộng số tokens quá nhiều sẽ làm phình DB lên ít nhất gấp đôi.

- - -

Một cách lỏng hơn nữa là sử dụng flags (xem `docs/.dict_matching.md`)
Với mỗi syllable (token) sẽ có flags 4-bits để xem token đó thuộc về vị trí thứ mấy của từ giả sử từ dài nhất chỉ có 4 âm tiết.

ví dụ:
"màu xanh" => màu-1,0,0,0 xanh-0,1,0,0,0
"cơ sở dữ liệu" => cơ-1,0,0,0 sở-0,1,0,0 dữ-1,0,1,0 liệu-0,1,0,1 vì "dữ liệu" là 1 từ riêng

với text "xanh lá màu xanh" => màu-1,0,0,0 xanh-1,1,0,0 lá-0,1,0,0
với input "xanh xanh" => xanh-1,1,0,0 thì sẽ khớp với text "xanh lá màu xanh" chưa thực sự ổn.

Note: với từ dài hơn thì dùng nhiều flags hơn, 8-bits là đủ cho từ dài 8 âm tiết, cover hết các trường hợp.

- - -

Giả sử với mọi 4-syllable words trong từ điển ta liệt kê mọi bi-gram (2-syllables) và index hết các bi-grams đó thì sao?

Với ví dụ trên thì bi-gram "xanh-xanh" ko có mặt trong text "xanh lá màu xanh" nên không match với input "xanh xanh".

Chỉ giữ lại khoảng 32k bi-gram đại diện cho từ điển mà có tuần suất xuất hiện trong corpus là cao nhất để làm đại diện.

Cũng có thể áp dụng BPE cho từ điển + tần suất xuất hiện để tìm ra tập 32k syllable-based sub-word n-grams tốt nhất để đại diện cho toàn bộ từ điển.