https://github.com/ku-nlp/jumanpp

```sh
mkdir -p build && cd build
cmake .. # -DCMAKE_CXX_FLAGS="-march=native"
make # -j
```

Juman++ is a general tool. It does not depend on Jumandic or Japanese Language (albeit there are some Japanese-specific functionality). See [this tutorial project](https://github.com/eiennohito/jumanpp-t9) which shows how to implement a something similar to a T9 text input for the case when there are no word boundaries in the input text.


https://www.slideshare.net/eiennohito/juman-v2-a-practical-and-modern-morphological-analyzer?from_action=save

A dictionary independent thread-safe library for morphological analysis using LATTICE-BASED SEGMENTATION optimized for n-best output.


- - -

https://github.com/Kensuke-Mitsuzawa/JapaneseTokenizers

https://github.com/taishi-i/nagisa

* Based on recurrent neural networks.
* The word segmentation model uses character- and word-level features [池田+].
* The POS-tagging model uses tag dictionary information [Inoue+].

- - -

http://www.phontron.com/kytea | https://github.com/neubig/kytea

Kyoto Text Analysis Toolkit (KyTea, pronounced "cutie")

KyTea employ Pointwise, provide Japanese and Chinese models for performing WORD SEGMENTATION, pronunciation estimation, and POS TAGGING (Japanese only), and can be trained to perform other tasks if you have data.

The most interesting technical point of KyTea is that it can be trained from PARTIALLY ANNOTATED DATA, which means that __you only have to annotate the important or difficult parts of sentences__, instead of whole sentences like traditional methods.

* Word Segmentation: It can separate an unsegmented text stream into appropriate units (words or morphemes).

* Tagging: It can estimate the tags for words such as POS tags and pronunciations. For pronunciations, it has the ability to estimate the pronunciation of unknown words.

All functionality is performed using a POINTWISE CLASSIFIER-BASED (SVM or logistic regression) approach, allowing for training on partially annotated training data. The classifiers are trained with LIBLINEAR.


http://www.phontron.com/paper/neubig11aclshort.pdf
Pointwise Prediction for Robust, Adaptable Japanese Morphological Analysis


- - -

http://viet.jnlp.org/kien-thuc-co-ban-ve-xu-ly-ngon-ngu-tu-nhien/thuat-toan-tach-tu-tokenizer/thuat-toan-tach-tu

Đối với tiếng Nhật, thuật toán phổ biến nhất là "Trọng số cực tiểu" : qui về bài toán đồ thị như sau: 
1. Tạo ra 2 đỉnh ảo là start, và end (đầu và cuối câu).
2. Lần lượt so sánh các đoạn với độ dài bất kì với 1 từ điển ngôn ngữ có sẵn.
3. Các đoạn có xuất hiện trong từ điển sẽ tạo thành 1 đỉnh mới trên đồ thị.
4. Trọng số giữa 2 đỉnh (2 đoạn phải liên tiếp nhau trong câu) được tính theo công thức f(i,j) với i,j là 2 từ.
5. Tìm đường đi từ đỉnh start đến đỉnh end có trọng số nhỏ nhất trên đồ thị đó. 

Trong bước 4, công thức f(i,j) thường được tính theo giá trị uni-gram (khả năng xuất hiện của 1 từ) và bi-gram (khả năng 2 từ xuất hiện liên tiếp nhau). Ngoài ra còn có thể có thêm 1 số yếu tố khác như từ loại, khả năng liên kết từ loại, ... cũng được sử dụng trong hàm f.

Trước đây, các giá trị này (trừ uni-gram và bi-gram được lấy từ cách thông kê corpus) thường được đánh giá bằng tay (do người thực hiện).  Nhưng với sự phát triển của lý thuyết máy học như Markov ẩn, CRFs, ... các giá trị này thường được tính 1 cách tự động. 

Trong bước 5, thuật toán tìm đường đi từ đỉnh start đến đỉnh end thường sử dụng thuật toán Viterbi với độ phức tạp thuật toán O(n) với n là độ dài câu cần tách.

- - -

DongDu 1.0 (release 03/10/2012)  http://viet.jnlp.org/dongdu

https://filedn.com/lit4DCIlHwxfS1gj9zcYuDJ/SNOW/DongDu-src.zip
https://filedn.com/lit4DCIlHwxfS1gj9zcYuDJ/SNOW/DongDu-code.pdf


Trong tiếng Việt, dấu cách không mang ý nghĩa phân tách các từ mà chỉ mang ý nghĩa phân tách các âm tiết với nhau. có khá nhiều các ngôn ngữ khác cũng gặp phải bài toán này, ví dụ như : tiếng Nhật, tiếng Trung, tiêng Hàn, … Mỗi một ngôn ngữ có 1 đặc điểm cú pháp khác nhau, nhưng nhìn chung, hướng tiếp cận chủ đạo ở tất cả các ngôn ngữ này là sử dụng máy học.

Pointwise được ứng dụng rộng rãi trong tiếng Nhật và tiếng Trung và thu được những kết quả rất tốt. Ngoài ra, nó còn ứng dụng tốt cho nhiều vấn đề khác nhau trong xử lý ngôn ngữ tự nhiên. Trong tiếng Việt, phương pháp này được ứng dụng trong bài toán thêm dấu cho tiếng Việt không dấu và thu được kết quả khá tốt (gần 95%).

Trong phương pháp pointwise, các nhãn sẽ được đánh giá một cách độc lập, và không tham khảo kết quả của các nhãn trước đó. Chính vì việc đánh giá độc lập như thế, mà phương pháp pointwise chỉ cần 1 từ điển vừa phải, và khá hiệu quả khi xác định những từ mới không có trong từ điển. Vì thế, phương pháp pointwise rất phù hợp với những ngôn ngữ không có nhiều dữ liệu như tiếng Việt.

Ngoài ra, vì các vị trí được đánh giá độc lập, các đặc trưng chỉ là thông tin văn bản xung quanh vị trí đó, nên pointwise có thể thực hiện được trên những dữ liệu không đầy đủ.

Phương pháp thích hợp nhất để thực hiện việc đánh giá độc lập này là sử dụng Support Vector Machine (SVM). SVM là phương pháp học máy đơn giản nhưng rất hiệu quả cho tập trung vào từng nhãn một cách độc lập, ít bị ảnh hưởng bởi các ví dụ sai trong dữ liệu huấn luyện. Ngoài ra, SVM cũng khá dễ dàng để thực hiện việc chọn lựa đặc trưng (features selection) để giảm kích thước dữ liệu model.

Phương pháp tiếp cận dạng pointwise sử dụng những thông tin xung quanh vị trí cần đánh giá, và thực hiện một cách độc lập với nhau. Chúng tôi sử dụng 3 dạng đặc trưng cơ bản trong phương pháp pointwise là: n-gram âm tiết, n-gram chủng loại của âm tiết, và đặc trưng từ điển.

* __N-gram âm tiết__: sử dụng n-gram của những âm tiết xung quanh vị trí đang đánh giá. Ở đây, chúng tôi sử dụng một cửa sổ có độ dài W, và chúng tôi chỉ sử dụng những âm tiết nằm trong cửa sổ này.

Với tiếng Việt, có khoảng 70% các từ gồm 2 âm tiết, và 14% các từ gồm 3 âm tiết. Vì lý do này, chúng tôi sẽ sử dụng W là 3. Ngoài ra, n thường là 1 và 2. Trong thực nghiệm, chúng tôi có sử dụng cả n = 3, nhưng kết quả không được cải thiện nhiều, và kích thước file model cũng tăng lên đáng kể.

* __N-gram chủng loại của âm tiết__: sử dụng chủng loại của các âm tiết trong cửa sổ. Trong nghiên cứu này, chúng tôi định nghĩa 4 chủng loại:
   o Âm tiết viết hoa (U): những âm tiết tiếng Việt có bắt đầu bằng chữ hoa.
   o Âm tiết viết thường (L : những âm tiết tiếng Việt chỉ gồm những chữ cái thường.
   o Số (N): gồm các chữ số.
   o Các loại khác (O): những kí hiệu, tiếng nước ngoài, và những âm tiết không nằm trong 3 loại trên.

* __Đặc trưng từ điển__: là những từ có trong từ điển

=> DongDu cho độ chính xác cao hơn vnTokenizer khoảng 1%. Về tốc độ xử lý, DongDu cũng nhanh hơn vnTokenizer khoảng 8 lần. Ngoài ra, DongDu đòi hỏi lượng RAM ít hơn vnTokenizer.