https://stackoverflow.com/questions/62664761/probability-of-hash-collision

Let's imagine we have a truly random hash function that hashes from strings to n-bit numbers. This means that there are 2^n possible hash codes, and each string's hash code is chosen uniformly at random from all of those possibilities. 

The birthday paradox specifically says that once you've seen roughly √(2k) items, there's a 50% chance of a collision, where k is the number of distinct possible outputs. In the case where the hash function hashes to an n-bit output, this means that you'll need roughly 2^n/2 hashes before you get a collision. 

If we pick hashes that output 64 bits; we'd need `2^32 ≈ 4.3*10^9` items hashed before there's a "reasonable" chance of a collision.

Với k uniq items đầu vào, bảng băm output ra n-bits, p là xác suất va chạm: 

k ≈ 2^{(n+1)/2} √p

Giả sử cần chứa 30m n-grams `k=30*10^6`, bảng băm đầu ra 64-bits `n=64` 
=> 30m = 2^32.5 x √p => √p = 0.0049390838 => p = 0.00002439454
Khả năng va chạm khi chứa 30m ids trong băm 64-bits là 25/m hay 1/40k.

Giả sử cần chứa 12m n-grams `k=12*10^6`, bảng băm đầu ra 64-bits `n=64` 
=> 12m = 2^32.5 x √p => √p = 0.00197563352 => p = 0.00000390312
Khả năng va chạm khi chứa 30m ids trong băm 64-bits là 4/m hay 1/250k.

- - -

Với 1,2,3,4-grams giữ nguyên giá trị đầu vào là `u64`
Với 5,6,7,8-grams thì hash về `u64` và có thể có va chạm nghĩa là bị mất đi

- - -

n-gram map rất đơn giản, chỉ cần map `u64` -> `u32` (dùng 2 mảng keys và counts),
Không cần xoá. Biết trước số lượng phần tử không vượt quá 30 triệu.
Làm sao để đếm count của từng key một thật nhanh!

=> Given a key làm sao tìm ra count thật nhanh để update count += 1

=> Có thể ghi tạm vào bảng đếm phụ rồi sau đó update vào bảng đếm chính?

1/ Viết lại hash_map.zig để tối ưu cho trường hợp riêng này
https://github.com/ziglang/zig/blob/master/lib/std/hash_map.zig

2/ Thử dùng 1 thư viện trie đã được tối ưu viết bằng C

- - -

Bài toán giản thể hơn nữa là đã có n-gram counts, load data và viết hàm look up key for count. Cũng dùng `u64` -> `u32` như trên, số lượng phần tử cố định, có va chạm thì loại bỏ. Hoặc dùng thêm fingerprint (bit-8..bit-15 => byte nằm giữa 2 token id đầu tiên) để phân biệt.

Sorted keys và counts tương ứng theo giá trị của key để look up dùng binary search.

- - -

Vì n-grams là đặc trưng vì mỗi gram mang một giá trị định sẵn nên có lẽ trie là data struct tốt nhất để thể hiện. Chọn trie kiểu nào cho hiệu quả.

Lưu ý, trie sẽ hỗ trợ prefix lookup, hash table không làm được. Số phần tử tại mỗi node là fixed, có thể xây dựng trước, sắp xếp để tìm kiếm cho nhanh rồi ghi ra files. Sau đó load vào là tối ưu luôn.

Có nhiều cách sắp xếp node.chidren, theo token_id values nếu muốn dùng binary search, hoặc search theo tần xuất xuất hiện để khớp với lượng tải trong thực tế sử dụng: cái hay xuất hiện để trên đầu để lấy ra cho nhanh.

Với node.children cũng có thể dùng một prob filter để kiểm tra nhanh xem 1 token_id bất kì có trong tập node.children hay không rồi mới tìm kiếm thật vì nếu item ko có trong tập thì luôn phải kiểm tra log(n) lần mới phát hiện ra (với cách sắp xếp children theo thứ tự keys).

Tham khảo source code của KenLM

- - -

## Tham khảo

https://twitter.com/lithdew/status/1425207623343689731

https://github.com/lithdew/rheia/commit/66e1cdbd4959298d4fd2349c771e3119127a963f#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5

1. B-Tree (tidwall/btree.c)
2. Adaptive Radix Tree (armon/libart)
3. Skiplist (MauriceGit/skiplist - ported to zig)
4. Red-black tree (ziglang/std-lib-orphanage)
5. Radix Tree (antirez/rax - ported to zig)
6. Binary Heap (ziglang/zig)
7. Adaptive Radix Tree (armon/libart - ported to zig)
8. Adaptive Radix Tree (travisstaloch/art.zig)

The adaptive radix tree showed the highest average overall throughput

https://zig.news/andrewrk/how-to-use-hash-map-contexts-to-save-memory-when-doing-a-string-table-3l33